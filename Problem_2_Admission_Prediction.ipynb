{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Graduate Admission Prediction using Decision Tree\n",
    "\n",
    "This notebook implements the second problem statement: building a Decision Tree Classifier to predict whether a student will be admitted to a foreign university based on their academic profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Setup and Data Loading\n",
    "\n",
    "First, we import the necessary libraries and load the `Admission_Predict.csv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the local CSV file\n",
    "file_path = 'd:\\\\ml\\\\LP-I\\\\Admission_Predict.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Data Pre-processing and Exploration\n",
    "\n",
    "We will perform the following pre-processing steps:\n",
    "1.  Clean up column names to remove any trailing spaces.\n",
    "2.  Drop the `Serial No.` column as it's just an index.\n",
    "3.  Convert the target variable `Chance of Admit` from a continuous probability to a binary outcome. We'll set a threshold of **0.75**; anything equal to or above is considered 'Admitted' (1), and anything below is 'Not Admitted' (0).\n",
    "4.  Check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names (remove leading/trailing spaces)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Drop the 'Serial No.' column\n",
    "df = df.drop('Serial No.', axis=1) # axis=1 indicates we are dropping a column\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Convert 'Chance of Admit' to a binary variable\n",
    "# We'll use a threshold of 0.75 for admission.\n",
    "df['Admitted'] = df['Chance of Admit'].apply(lambda x: 1 if x >= 0.75 else 0)\n",
    "\n",
    "# Drop the original 'Chance of Admit' column\n",
    "df = df.drop('Chance of Admit', axis=1)\n",
    "\n",
    "print(\"\\nDataset after creating binary 'Admitted' column:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our features (X) and the new binary target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df.drop('Admitted', axis=1)\n",
    "y = df['Admitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Perform Train-Test Split\n",
    "\n",
    "We will split the dataset into a training set (80%) and a testing set (20%) to evaluate the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Implement and Train the Decision Tree Classifier\n",
    "\n",
    "We will now create an instance of the `DecisionTreeClassifier` and train it using our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree model instance\n",
    "# Using random_state for reproducibility\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree Classifier model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Evaluate Model Performance\n",
    "\n",
    "With the model trained, we can make predictions on our test data and evaluate its performance using accuracy, precision, and recall. We will also display a full classification report and a confusion matrix for a more detailed view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Performance Evaluation:\")\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "# Display the full classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Admitted', 'Admitted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the Confusion Matrix\n",
    "\n",
    "A confusion matrix helps us visualize the model's performance in terms of true positives, true negatives, false positives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',  # fmt means integer format, annot means annotate cells\n",
    "            xticklabels=['Not Admitted', 'Admitted'], \n",
    "            yticklabels=['Not Admitted', 'Admitted'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We have successfully implemented a basic Decision Tree Classifier to predict graduate school admissions.\n",
    "\n",
    "**Code Quality and Clarity:**\n",
    "- The notebook is structured logically according to the tasks in the problem statement.\n",
    "- Each step is explained with comments and markdown, making the process easy to follow.\n",
    "- The code uses standard libraries and follows best practices for a minimal implementation, such as setting a `random_state` for reproducibility.\n",
    "\n",
    "**Model Interpretation:**\n",
    "- **Accuracy:** The overall correctness of the model.\n",
    "- **Precision:** Out of all the students the model predicted would be admitted, this is the percentage that was actually admitted. A high precision is important to avoid giving false hope.\n",
    "- **Recall:** Out of all the students who were actually admitted, this is the percentage that the model correctly identified. \n",
    "\n",
    "**Potential Improvements:**\n",
    "- **Hyperparameter Tuning:** The performance of the Decision Tree can be improved by tuning parameters like `max_depth`, `min_samples_split`, and `criterion`.\n",
    "- **Cross-Validation:** To get a more robust measure of performance, k-fold cross-validation could be used instead of a single train-test split.\n",
    "- **Feature Scaling:** While not strictly necessary for Decision Trees, scaling features can be good practice, especially if other models (like SVM or Logistic Regression) are to be tested.\n",
    "- **Threshold Tuning:** The admission threshold of 0.75 was an assumption. This could be tuned to optimize for either precision or recall, depending on the counsellor's goal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
